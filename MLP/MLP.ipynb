{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i have two nodes for input and one node for output, there is a one hidden layer with hidden_count number of nodes(init(hidden_count, alpha)), (when i changed it from 5 to 8 it took more time and the resault got a little better _90.7 to 91.5_ and time around 5 sec to 25 sec...) \n",
    "*at the end of report i printed the points that were incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 [-0.586110177649249, -1.50363417532463, -1.28089947174288, -0.023598126223051, 1.33647812419478, 0.357641911027138, -0.267087831778927, -1.25246127938213, -0.486626837029913, 1.35142920975526]\n",
      "2.97797123593957 -3.04444701414054 4.94845678331942 -3.00517265841451\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "import random\n",
    "\n",
    "file = open(\"train\", \"r\")\n",
    "count = 0\n",
    "in_x = []\n",
    "in_y = []\n",
    "t = []\n",
    "while 1:\n",
    " \n",
    "    line = file.readline()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "    line = list(line.split())\n",
    "    in_x.append(float(line[0]))\n",
    "    in_y.append(float(line[1]))\n",
    "    t.append(int(line[2]))\n",
    "    #print(in_x[-1], in_y[-1], t[-1])\n",
    "    count += 1\n",
    "print(len(in_x), in_x[:10])\n",
    "print(max(in_x), min(in_x), max(in_y), min(in_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the first random values (between -0.5 and 0.5) and +1 is for bias value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10054693782136348, 0.08154030636444798, 0.44237808856641925, -0.3811777105096721, 0.25004901689815096], [-0.12302832259318297, 0.3879858365929586, 0.374978888415581, 0.4132414799176106, -0.33706161375952803]] [-0.018391279890557444, 0.03709925923559865, 0.1596915685433138, 0.3545132794536243, -0.197756731834846]\n"
     ]
    }
   ],
   "source": [
    "def init(hidden_count, a):\n",
    "    global v, w, z, alpha, bias_v, bias_w\n",
    "    alpha = a\n",
    "    z = [0 for i in range(hidden_count)]\n",
    "    bias_v = [(random.random() - 0.5) for i in range(hidden_count)]\n",
    "    v = [[(random.random() - 0.5) for i in range(hidden_count)] for j in range(2)]\n",
    "    w = [(random.random() - 0.5)for i in range(hidden_count)]\n",
    "    bias_w = random.random() - 0.5\n",
    "init(5, 0.02)\n",
    "print(v, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function(sigmoid) and it's derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    #print(x)\n",
    "    if x > 500: return 1\n",
    "    if x < -500:return 0\n",
    "    return 1.0 / (1.0 + exp(-x))\n",
    "def df(x):\n",
    "    return f(x) * (1.0 - f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the values with one input (x,y,t)\n",
    "(terminology is like the class slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(x, y, t, res = 0):\n",
    "    global v, w, z, alpha, bias_v, bias_w\n",
    "    \n",
    "    z_in = []\n",
    "    for j in range(len(z)):\n",
    "        z_in.append(bias_v[j] + v[0][j] * x + v[1][j] * y)\n",
    "        z[j] = f(z_in[-1])\n",
    "    out = bias_w + sum([w[i] * z[i] for i in range(len(z))]) \n",
    "    out_act = f(out)\n",
    "    if res : return out_act\n",
    "    # returning for error and update\n",
    "    delta = (t - out_act) * df(out)\n",
    "    delta_w = [alpha * delta * z[i] for i in range(len(z))]\n",
    "    delta_bias_w = alpha * delta\n",
    "    \n",
    "    delta_in = [delta * w[j] for j in range(len(z))]\n",
    "    delta = [delta_in[i] * df(z_in[i]) for i in range(len(z))]\n",
    "    #print(delta)\n",
    "    delta_v0 = [alpha * delta[j] * x for j in range(len(z))]\n",
    "    delta_v1 = [alpha * delta[j] * y for j in range(len(z))]\n",
    "    delta_bias_v = [alpha * delta[j] for j in range(len(z))]\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        w[i] += delta_w[i] \n",
    "        v[0][i] += delta_v0[i]\n",
    "        v[1][i] += delta_v1[i]\n",
    "        bias_v[i] += delta_bias_v[i]\n",
    "        \n",
    "    bias_w += delta_bias_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "init(5, .01)\n",
    "for i in range(400):\n",
    "    for j in range(4000):\n",
    "        train_one(in_x[j], in_y[j], t[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.262067347178126, 1.7692711607656046, -1.3274107589944268, -1.887292372463022, 1.7812517385180215], [0.14378938404170624, 0.40476468367712776, -0.21530310374284073, -0.4383637496790415, 0.62858991478586]] [1.1682783625315516, 1.9418454920700423, -1.4375403623765952, -2.2135577881958195, 1.9530999034865162]\n"
     ]
    }
   ],
   "source": [
    "print(v, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i had this crazy bug that instead of f'(x) = f(x) * (1-f(x)) it was f'(x) = x * (1-x) and i changed a lot other parts for it... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "file = open(\"test\", \"r\")\n",
    "count = 0\n",
    "correct = 0\n",
    "while 1:\n",
    " \n",
    "    line = file.readline()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "    line = list(line.split())\n",
    "    a = (float(line[0]))\n",
    "    b = (float(line[1]))\n",
    "    c = (int(line[2]))\n",
    "    if abs(c - train_one(a,b,c,1)) < 0.4:\n",
    "        correct += 1\n",
    "\n",
    "    #print(in_x[-1], in_y[-1], t[-1])\n",
    "    \n",
    "    count += 1\n",
    "print(correct / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.633687809518789 0.469846539860649\n",
      "0.200443114488755 -1.39076610484662\n",
      "0.020529179999515 -0.741064312936821\n",
      "0.052981422316654 -0.417082523824423\n",
      "0.230474265066374 1.32188830412696\n",
      "0.208502349528497 -1.50069896375079\n",
      "0.504925712957714 1.33289141417598\n",
      "0.140151446933644 -0.269437066924355\n",
      "-0.025901124087941 -0.637463169792611\n",
      "-0.772839077233568 2.54892115425235\n",
      "0.043788091779218 -0.245058038136038\n",
      "0.201886481629137 -1.52495389580395\n",
      "-0.182554291108849 -0.591716871650174\n",
      "-0.299854678639638 0.081549971845352\n",
      "-0.748389402883773 -0.519726810513816\n",
      "-0.180832995475311 -1.37166912426394\n",
      "1.00480338161153 -2.24461117748409\n",
      "-0.287569052828006 0.104110966761412\n",
      "0.22535723175402 -1.73359793273308\n",
      "-0.842592943376905 -1.40771658085872\n",
      "0.081527123525265 -0.352858172528667\n",
      "-0.267573699467927 -1.60862593686852\n",
      "0.523300924134902 -1.22786948924675\n",
      "0.403799434702408 -1.22460591754875\n",
      "0.252981545294199 -1.17197595898611\n",
      "0.028905774508546 -0.723527073613366\n",
      "0.959271009910824 -2.68560885690102\n",
      "0.087625271852143 -1.15046630113484\n",
      "0.608439576439839 -2.1300329732817\n",
      "0.339420145067856 -1.93150784958821\n",
      "-0.353927968381387 1.62339839428282\n",
      "0.244887479201154 -1.5344014704552\n",
      "0.627082730555767 -1.52627999732123\n",
      "0.174606710831783 -0.870686657405464\n",
      "-1.38032855874806 -0.501020857904726\n",
      "0.314398238897843 -1.16014834489779\n",
      "-0.054660028790205 -0.817716556338169\n",
      "-0.366880132683892 0.464805374917938\n",
      "0.349588231390292 -0.530020989293143\n",
      "0.459601935637973 -1.17800048880264\n",
      "0.255780179552576 -1.40176539082439\n",
      "-0.505300538859998 0.185478543450964\n",
      "0.245334570065815 -1.07046388183373\n",
      "0.170334097990891 -1.39779942516055\n",
      "-0.345823497280509 1.45474119736962\n",
      "0.013138290934711 -0.986353136619641\n",
      "0.258174188974907 -0.580048364942101\n",
      "-0.035052916403317 -0.244040625126808\n",
      "-0.095021450832459 -1.13767391493268\n",
      "0.118394146440442 -0.51631387286574\n",
      "0.166966646807328 -0.200905536461674\n",
      "1.47196233077776 -0.867504204781095\n",
      "-0.038696093320545 -1.8207771025633\n",
      "0.119736598443221 -0.053013863927198\n",
      "0.051386738206732 -0.251445675415783\n",
      "0.426303697409958 -1.43153846639376\n",
      "0.663960821546651 -2.08258177380167\n",
      "0.172348642694422 -3.06977631344144\n",
      "0.192195969048976 -1.01659430320039\n",
      "-0.737875761782846 -0.370980028414214\n",
      "-0.614907168801596 -0.744195069628493\n",
      "-0.695016250295675 -0.878230560647033\n",
      "0.196811883889467 -1.48146296725201\n",
      "-0.838963169871462 1.8599902623823\n",
      "0.105072550283343 -0.531144378456635\n",
      "-0.145006908157077 0.11465406981449\n",
      "-0.615473710949184 -0.90939480381031\n",
      "0.083231915990881 -1.13821337602539\n",
      "-0.791026064125818 -1.45978524871262\n",
      "0.155568425076102 -1.52193832476463\n",
      "0.82844215041097 -1.77990153141609\n",
      "0.078585127121018 0.24185496171936\n",
      "-0.234147373763754 -0.35777408912334\n",
      "0.646464802394433 -2.26471250931348\n",
      "0.117891560443768 -0.243519939074651\n",
      "-0.285443068054445 -0.128855091974938\n",
      "-0.339426995338057 -0.867804208821041\n",
      "1.33726700946565 -1.5841345527435\n",
      "0.227314721301219 -1.42411859589735\n",
      "0.498186186779213 -1.54366599380296\n",
      "0.359236888157046 -1.47072800221201\n",
      "0.661232593457221 -2.58006970462438\n",
      "-0.064580463633355 -0.016544199312989\n",
      "-0.587713279562207 -0.917138591852879\n",
      "-0.237249985639707 0.03265177891414\n"
     ]
    }
   ],
   "source": [
    "file = open(\"test\", \"r\")\n",
    "count = 0\n",
    "correct = 0\n",
    "while 1:\n",
    " \n",
    "    line = file.readline()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "    line = list(line.split())\n",
    "    a = (float(line[0]))\n",
    "    b = (float(line[1]))\n",
    "    c = (int(line[2]))\n",
    "    if abs(c - train_one(a,b,c,1)) < 0.4:\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(a,b)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
